---
layout: detail-page
back_url: /recommended-blogs
back_text: Back to Recommended Blogs
breadcrumb_url: /recommended-blogs
breadcrumb_text: Recommended Blogs
title: Embrace The Red
focus: AI security, Red Teaming, and Azure
category: AI & Cloud Security
description: Michael Selinger's research at the forefront of AI safety and cloud-based offensive operations.
image: recommended-blogs/embrace-the-red.webp
website: https://embracethered.com/blog/
rss_feed: https://embracethered.com/blog/index.xml
---

## Subscribe
**RSS Feed:** [{{ page.rss_feed }}]({{ page.rss_feed }})

---

Embrace The Red is a critical resource for understanding the security implications of the AI revolution and modern Azure environments.

## Key Research Areas
- **Prompt Injection**: Discovering and defending against indirect prompt injection in LLMs.
- **AI Agent Security**: Exploiting autonomous agents and integrated AI systems.
- **Azure Red Teaming**: Advanced tactics for lateral movement and privilege escalation in Microsoft Cloud.

## Why Follow This Blog

Johann Rehberger's Embrace The Red has become the definitive resource for AI security research, particularly around prompt injection and LLM vulnerabilities. As AI systems become integrated into enterprise workflows, understanding how to attack and defend these systems is essential for modern security practitioners.

## Key Topics Covered

### AI & LLM Security
- **Prompt Injection**: Direct and indirect prompt injection attacks
- **Data Exfiltration**: Extracting sensitive information through AI systems
- **Agent Exploitation**: Attacking autonomous AI agents
- **Plugin Security**: Vulnerabilities in AI system extensions
- **Guardrail Bypass**: Circumventing AI safety mechanisms

### Microsoft Azure Security
- **Identity Attacks**: Azure AD exploitation techniques
- **Privilege Escalation**: Elevating permissions in Azure environments
- **Lateral Movement**: Moving between Azure services
- **Managed Identities**: Exploiting Azure identity features
- **Configuration Weaknesses**: Common Azure misconfigurations

### Cloud Red Teaming
- **Microsoft 365**: Office 365 and related service attacks
- **Azure Services**: Specific service exploitation techniques
- **Hybrid Environments**: On-premises to cloud attack paths
- **Token Theft**: Credential and token-based attacks

### Offensive Tooling
- **Tool Development**: Creating red team tools
- **Automation**: Scripting attack techniques
- **Detection Evasion**: Bypassing security controls
- **Persistence**: Maintaining access in cloud environments

## Research Methodology

### Practical Exploitation
Embrace The Red focuses on:
- Real-world attack scenarios
- Reproducible techniques
- Defensive recommendations
- Tool releases

### Responsible Disclosure
Research includes:
- Vendor coordination
- Bug bounty participation
- Community contribution
- Detailed writeups

## Notable Research

### AI Security Pioneering
Leading work in:
- Defining prompt injection taxonomy
- Demonstrating AI agent vulnerabilities
- Publishing practical attack techniques
- Influencing AI security standards

### Azure Security Research
Comprehensive coverage of:
- Identity-based attacks
- Service-specific vulnerabilities
- Configuration exploitation
- Detection and defense

## Who Should Follow

### AI Security Researchers
Essential for understanding LLM and AI system vulnerabilities.

### Red Team Operators
Practical techniques for Azure and Microsoft 365 assessments.

### Cloud Security Engineers
Defensive insights for Azure environments.

### AI/ML Engineers
Security awareness for building safer AI systems.

### Security Architects
Understanding AI risks for secure design.

## Best Practices for Following

### AI Security Focus
- Understand prompt injection fundamentals
- Test AI systems in your environment
- Implement AI-specific security controls

### Azure Security
- Apply techniques in authorized assessments
- Build detection capabilities
- Stay current with Azure changes

### Practical Application
- Set up lab environments
- Practice techniques safely
- Contribute to the community

## Recommended Posts

### Must-Read Research
1. **"Indirect Prompt Injection Explained"** - Foundational research on one of the most significant AI vulnerability classes
2. **"Hacking Google Bard - From Prompt Injection to Data Exfiltration"** - Practical demonstration of AI system exploitation
3. **"ChatGPT Plugin Vulnerabilities"** - Analysis of security issues in AI plugin ecosystems
4. **"Azure AD Attack Paths"** - Comprehensive guide to Azure identity exploitation
5. **"Exfiltrating Data from AI Agents"** - Techniques for extracting sensitive information through LLMs

### For AI Security Beginners
Start with the prompt injection fundamentals before exploring advanced agent attacks.

### For Cloud Red Teamers
Focus on the Azure-specific posts for immediately applicable techniques.

### For Defenders
Study attack patterns to build detection and prevention capabilities.

Embrace The Red represents essential reading as AI systems become central to enterprise operations, providing the security community with critical research on emerging attack vectors and defensive strategies.